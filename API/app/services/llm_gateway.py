from __future__ import annotations
import json
import os
import asyncio
import logging
from typing import Any, Dict, List, Optional
from openai import OpenAI

CLASSIFIER_MODEL = os.getenv("CLASSIFIER_MODEL", "gpt-4o-mini")
ANSWERER_MODEL   = os.getenv("ANSWERER_MODEL",   "gpt-4o")

_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
body_logger = logging.getLogger("debug.body")  # ì „ìš© ë¡œê±°

# def _to_transcript(chat_meta: Optional[Dict[str, Any]], user_text: str) -> str:
#     """
#     chat_meta(ì´ì „ ëŒ€í™”)ì™€ í˜„ì¬ user_textë¥¼ ì‚¬ëŒì´ ì½ëŠ” ëŒ€í™” ë¡œê·¸ ë¬¸ìì—´ë¡œ ì§ë ¬í™”.
#     chat_metaê°€ dict/str/None ì–´ë–¤ í˜•íƒœë¡œ ì™€ë„ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬.
#     """
#     lines: List[str] = []
#     if isinstance(chat_meta, dict):
#         # í‚¤ë¥¼ ì •ë ¬í•´ ì¬í˜„ì„± í™•ë³´ (user0, assistant0, user1... ê°™ì€ í˜•íƒœë¥¼ ê¸°ëŒ€)
#         for k in sorted(chat_meta.keys(), key=lambda x: str(x)):
#             role = "user" if "user" in str(k).lower() else ("assistant" if "assistant" in str(k).lower() else "note")
#             lines.append(f"{role}: {chat_meta[k]}")
#     elif isinstance(chat_meta, list):
#         # ["user: ...", "assistant: ..."] ê°™ì€ ê²½ìš°
#         for item in chat_meta:
#             lines.append(str(item))
#     elif isinstance(chat_meta, str):
#         lines.append(chat_meta.strip())

#     # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ì„ ë§ˆì§€ë§‰ì— ì¶”ê°€
#     if user_text:
#         lines.append(f"user: {user_text.strip()}")

#     # ë¹„ì–´ìˆìœ¼ë©´ í˜„ì¬ ì…ë ¥ë§Œ ë°˜í™˜
#     if not lines:
#         return f"user: {user_text.strip()}"
#     return "\n".join(lines)

# 1) ê°„ë‹¨ ìš”ì•½ê¸° (mini ëª¨ë¸ë¡œ 1~2ë¬¸ì¥ ìš”ì•½)
def summarize_history_for_context(chat_meta: Optional[Dict[str, Any] | List[str] | str], max_chars: int = 1200) -> str:
    """
    ê³¼ê±° ëŒ€í™”ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½. ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.
    ë§¤ìš° ì €ë¹„ìš©/ì €ì˜¨ë„ í˜¸ì¶œì„ ê°€ì •. (ì›í•˜ë©´ ë™ê¸°/ë¹„ë™ê¸° ë¶„ë¦¬)
    """
    # ì›ìë£Œ ë¬¸ìì—´í™”(ê¸¸ë©´ ì»·)
    raw = ""
    if isinstance(chat_meta, dict):
        # í‚¤ ì •ë ¬ì€ ê¸°ì¡´ ë¡œì§ ìœ ì§€
        lines = []
        for k in sorted(chat_meta.keys(), key=lambda x: str(x)):
            role = "user" if "user" in str(k).lower() else ("assistant" if "assistant" in str(k).lower() else "note")
            lines.append(f"{role}: {chat_meta[k]}")
        raw = "\n".join(lines)
    elif isinstance(chat_meta, list):
        raw = "\n".join(str(x) for x in chat_meta)
    elif isinstance(chat_meta, str):
        raw = chat_meta.strip()
    raw = (raw or "").strip()[:max_chars]

    if not raw:
        return ""

    prompt = (
        "ë‹¤ìŒ ëŒ€í™” ë¡œê·¸ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. í•µì‹¬ ì˜ë„/ì£¼ì œë§Œ ë³´ì¡´í•˜ê³  ì‚¬ì¡±ì€ ì œê±°í•˜ì„¸ìš”.\n"
        "ì¶œë ¥ì€ í•œêµ­ì–´ 1~2ë¬¸ì¥, ë©”íƒ€/ë¶ˆë¦¿/ì½”ë“œë¸”ë¡ ê¸ˆì§€.\n\n"
        f"<<LOG>>\n{raw}\n<<END>>"
    )
    try:
        resp = _client.chat.completions.create(
            model=CLASSIFIER_MODEL,  # mini ì‚¬ìš©
            messages=[
                {"role": "system", "content": "ëŒ€í™” ìš”ì•½ê°€. ë°˜ë“œì‹œ 1~2ë¬¸ì¥ìœ¼ë¡œë§Œ."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.0,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception:
        return ""
    
def extract_sticky_entities(chat_meta: Optional[Dict[str, Any] | List[str] | str],
                            entity_hints: Optional[Dict[str, List[str]]] = None,
                            max_lookback: int = 8) -> Dict[str, Optional[str]]:
    """
    ìµœê·¼ ëŒ€í™”(ìµœëŒ€ max_lookback ë©”ì‹œì§€ ë²”ìœ„)ì—ì„œ ë³´í—˜ì‚¬/ìƒí’ˆ ë‹¨ì¼ í›„ë³´ë¥¼ ë½‘ì•„ Stickyë¡œ ì‚¬ìš©.
    - entity_hints: {"insurers": [...], "products": [...]} ì£¼ë©´ ì •í™•ë„â†‘ (ì„ íƒ)
    - ì¶©ëŒ(í›„ë³´ê°€ 2ê°œ ì´ìƒ)ì´ë©´ None ë°˜í™˜ â†’ ìƒì† ì¤‘ë‹¨(ë³´ìˆ˜ì )
    """
    texts: List[str] = []
    if isinstance(chat_meta, dict):
        # í‚¤ ì •ë ¬ í›„ ìµœê·¼ ë©”ì‹œì§€ ëª‡ ê°œë§Œ
        pairs = [(str(k), str(v)) for k, v in chat_meta.items()]
        pairs.sort(key=lambda kv: kv[0])
        texts = [v for _, v in pairs][-max_lookback:]
    elif isinstance(chat_meta, list):
        texts = [str(x) for x in chat_meta][-max_lookback:]
    elif isinstance(chat_meta, str):
        texts = [chat_meta.strip()]

    blob = "\n".join(texts).strip()
    if not blob:
        return {"insurer": None, "product": None}

    insurers = set()
    products = set()

    # íŒíŠ¸ ì‚¬ì „ì— ê¸°ë°˜í•œ ì •í•© ì¶”ì¶œ (ì •í™•Â·ê²°ì •ì )
    if entity_hints:
        for name in (entity_hints.get("insurers") or []):
            if name and name.lower() in blob.lower():
                insurers.add(name)
        for name in (entity_hints.get("products") or []):
            if name and name.lower() in blob.lower():
                products.add(name)

    # íŒíŠ¸ê°€ ì—†ê±°ë‚˜ ëª»ì°¾ì€ ê²½ìš°: ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±(ê´„í˜¸/ë³´í—˜/ì‹¤ì† ë“± íŒ¨í„´)
    import re
    if not insurers:
        # ì˜ˆ: ë¡¯ë°, í•œí™”, ì‚¼ì„±, í˜„ëŒ€ ë“± ê³ ìœ ëª…ì‚¬ íŒ¨í„´ì„ ì¶”ê°€ë¡œ ë„£ì„ ìˆ˜ ìˆìŒ
        m = re.findall(r"(ë¡¯ë°|í•œí™”|ì‚¼ì„±|í˜„ëŒ€|KB|ë©”ë¦¬ì¸ |í¥êµ­|DB|êµë³´|ë¼ì´ë‚˜|ë†í˜‘|ë™ì–‘|ìš°ì²´êµ­)", blob)
        insurers.update(m)
    if not products:
        # ì˜ˆ: 'ë³´í—˜', 'ì‹¤ì†', 'ë¬´ë°°ë‹¹', 'ê°„í¸', 'ì˜ë£Œë¹„' ë“± í¬í•¨ëœ ìƒí’ˆëª… ë¼ì¸ ì¶”ì¶œ
        for line in blob.splitlines():
            if ("ë³´í—˜" in line) or ("ì‹¤ì†" in line):
                # ë„ˆë¬´ ê¸´ ì¤„ì€ ì œì™¸
                cand = line.strip()
                if 3 <= len(cand) <= 80:
                    products.add(cand)

    # ì¶©ëŒ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ ë°°ì œ
    insurer = list(insurers)[0] if len(insurers) == 1 else None
    product = list(products)[0] if len(products) == 1 else None
    return {"insurer": insurer, "product": product}


# 2) ë¶„ë¥˜ê¸° í˜¸ì¶œ: ë©”ì‹œì§€ êµ¬ì„± ë°©ì‹ ë³€ê²½
def run_classifier_llm(user_text: str,
                       chat_meta: Optional[Dict[str, Any]] = None,
                       entity_hints: Optional[Dict[str, List[str]]] = None) -> Dict[str, Any]:
    """
    ìµœì‹  ë°œí™” ìš°ì„  + Sticky ì—”í‹°í‹° ìƒì†.
    """
    SYSTEM_RULES = (
        "ë‹¹ì‹ ì€ ë³´í—˜ ë„ë©”ì¸ ëŒ€í™” ë¼ìš°í„°ì…ë‹ˆë‹¤. ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        "ì›ì¹™:\n"
        "1) HISTORYëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤. CURRENT_QUESTIONê³¼ ì¶©ëŒí•˜ë©´ CURRENT_QUESTIONì„ ìš°ì„ í•©ë‹ˆë‹¤.\n"
        "2) primary_flow/ì—”í„°í‹°/ì˜ë„ëŠ” ìµœì‹  ë°œí™”ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.\n"
        "3) í™˜ê¸‰ê¸ˆ ê´€ë ¨ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ì´ ë¶„ë¥˜í•©ë‹ˆë‹¤:\n"
        "   - ì‚¬ìš©ìê°€ ë°›ì„ 'í™˜ê¸‰ê¸ˆì˜ ì•¡ìˆ˜'ë¥¼ ì§ì ‘ ë¬»ëŠ” ì§ˆë¬¸(ìˆ«ì/ê³„ì‚°/ê¸ˆì•¡ ë²”ìœ„ ìš”ì²­ í¬í•¨)ë§Œ REFUND\n"
        "   - ê·¸ ì™¸ í™˜ê¸‰ê¸ˆ ì ˆì°¨/ì¡°ê±´/ì„œë¥˜/ê°€ëŠ¥ ì—¬ë¶€/ì•½ê´€ ì¡°í•­ ë“±ì€ TERMS\n"
        "4) CURRENT_QUESTIONì— íŠ¹ì • ë³´í—˜ì‚¬/ìƒí’ˆëª…ì´ ì–¸ê¸‰ë˜ë©´, entities.insurer/entities.productë¥¼ ë°˜ë“œì‹œ ì±„ìš°ê³ ,\n"
        "   primary_flowê°€ TERMSì¼ ë•Œ retrieval_suggestionì€ ë°˜ë“œì‹œ 'on'ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n"
        "5) CURRENT_QUESTIONì— ë³´í—˜ì‚¬/ìƒí’ˆëª…ì´ ì—†ë”ë¼ë„, [STICKY_ENTITIES]ì— ë‹¨ì¼ í›„ë³´ë¡œ ì œê³µëœ ê°’ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê°’ì„ ìƒì†í•˜ì—¬ ì±„ì›ë‹ˆë‹¤.\n"
        "   ë‹¨, í›„ë³´ê°€ ë‹¤ìˆ˜/ëª¨í˜¸í•˜ë©´ ìƒì†í•˜ì§€ ë§ˆì„¸ìš”.\n"
        "6) ì—”í‹°í‹°ëŠ” NULLì„ ë‚¨ë°œí•˜ì§€ ë§ê³ , CURRENT_QUESTION ë˜ëŠ” STICKYì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ ê²ƒì€ ë°˜ë“œì‹œ ì±„ì›ë‹ˆë‹¤.\n"
        "ìŠ¤í‚¤ë§ˆ:\n"
        "{"
        "\"primary_flow\":\"TERMS|REFUND|RECOMMEND|GENERAL|FALLBACK\","
        "\"confidence\":0.0,"
        "\"entities\":{"
        "  \"insurer\":null,\"product\":null,\"version\":null,"
        "  \"topic\":null,\"icd10_candidate\":null,"
        "  \"product_type\":null,\"focus_topics\":[]"
        "},"
        "\"retrieval_suggestion\":\"on|off|auto\","
        "\"reasons\":\"ìµœì†Œ ê·¼ê±°\","
        "\"tags\":[\"í‚¤ì›Œë“œ\"],"
        "\"text\":\"HISTORYì™€ CURRENT_QUESTIONì„ í•©ì³ 1~2ë¬¸ì¥ ìš”ì•½(ë³´í—˜ì‚¬/ìƒí’ˆì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í¬í•¨)\""
        "}\n"
        "ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•˜ê³  ì—¬ë¶„ í…ìŠ¤íŠ¸/ì½”ë“œë¸”ë¡ì„ ê¸ˆì§€í•©ë‹ˆë‹¤.\n"
    )

    # ê¸°ì¡´ ìš”ì•½ ìœ ì§€
    hist_summary = summarize_history_for_context(chat_meta)
    history_block = f"[HISTORY]\n{hist_summary}" if hist_summary else "[HISTORY]\n(ì—†ìŒ)"

    # ğŸ”§ NEW: Sticky ì—”í‹°í‹° ì¶”ì¶œ
    sticky = extract_sticky_entities(chat_meta, entity_hints=entity_hints, max_lookback=8)
    sticky_block = "[STICKY_ENTITIES]\n" \
                   f"insurer: {sticky.get('insurer') or '(ì—†ìŒ)'}\n" \
                   f"product: {sticky.get('product') or '(ì—†ìŒ)'}"

    current = f"[CURRENT_QUESTION]\n{(user_text or '').strip()}"

    messages = [
        {"role": "system", "content": SYSTEM_RULES},
        {"role": "assistant", "content": history_block},     # ì°¸ê³ ìš©
        {"role": "assistant", "content": sticky_block},      # ğŸ”§ ìƒì†ìš© êµ¬ì¡°í™” ì»¨í…ìŠ¤íŠ¸
        {"role": "user", "content": current},                # ìµœì‹  ì§ˆë¬¸(ìµœìš°ì„ )
    ]

    # (ë¡œê¹…ì€ ê¸°ì¡´ body_logger ë¡œì§ ì¬ì‚¬ìš©)
    try:
        payload_str = "\n############ [LLM DEBUG] ############\n"
        payload_str += json.dumps(messages, ensure_ascii=False, default=str)
    except Exception:
        payload_str = "\n############ [LLM DEBUG] ############\n" + str(messages)
    body_logger.info(payload_str)

    resp = _client.chat.completions.create(
        model=CLASSIFIER_MODEL,
        messages=messages,
        temperature=0.0,
        response_format={"type": "json_object"}
    )
    content = (resp.choices[0].message.content or "").strip()
    body_logger.info("\n############ [LLM DEBUG2] ############\n" + content)

    try:
        result = json.loads(content)
    except Exception:
        # ì‹¤íŒ¨ ì‹œ ì•ˆì „ê°’
        return {
            "primary_flow": "GENERAL",
            "confidence": 0.3,
            "entities": {
                "insurer": None, "product": None, "version": None,
                "topic": None, "icd10_candidate": None,
                "product_type": None, "focus_topics": [],
            },
            "retrieval_suggestion": "auto",
            "reasons": "parse_error",
            "tags": [],
            "text": user_text or ""
        }

    # ===== í™˜ê¸‰ê¸ˆ ê´€ë ¨ë‚´ìš© ë³´ì • ì‹œì‘ =====
    entities = result.get("entities", {}) or {}
    insurer = (entities.get("insurer") or "").strip() or None
    product = (entities.get("product") or "").strip() or None
    topic   = (entities.get("topic") or "").strip() or None

    if (not insurer or not product) and sticky:
        s_ins = sticky.get("insurer")
        s_prod = sticky.get("product")
    # í˜„ì¬ê°€ ë¹„ì–´ìˆê³  stickyì— ë‹¨ì¼ í›„ë³´ê°€ ìˆìœ¼ë©´ ìƒì†
    if not insurer and s_ins:
        entities["insurer"] = s_ins
        insurer = s_ins
    if not product and s_prod:
        entities["product"] = s_prod
        product = s_prod
    result["entities"] = entities

    # (A) ê¸ˆì•¡ ì§ˆë¬¸ íŒë³„(ì •ê·œì‹/í‚¤ì›Œë“œ)
    ask_amount_like = False
    q = (user_text or "").lower()
    # ê¸ˆì•¡/ê³„ì‚°/ì–¼ë§ˆ/ì›/ë§Œì›/ë¹„ìœ¨/ì‚°ì¶œ ë“± ê°„ë‹¨ í‚¤ì›Œë“œì™€ ìˆ«ì íŒ¨í„´
    if any(k in q for k in ["ì–¼ë§ˆ", "ê¸ˆì•¡", "í™˜ê¸‰ë¥ ", "ê³„ì‚°", "ì‚°ì¶œ", "ë¹„ìœ¨", "ì–¼ë§ˆë‚˜ ë‚˜ì˜¤", "ì˜ˆìƒ í™˜ê¸‰"]):
        ask_amount_like = True
    # ìˆ«ì/í†µí™” íŒ¨í„´ë„ íŒíŠ¸
    import re
    if re.search(r"\b\d+(\,\d{3})*(ì›|ë§Œì›|,?\s?won)\b", q):
        ask_amount_like = True

    # (B) 1ì°¨ ë¶„ë¥˜ ë³´ì •: ê¸ˆì•¡ ì§ˆë¬¸ë§Œ REFUND
    if ask_amount_like:
        result["primary_flow"] = "REFUND"
    else:
        # í™˜ê¸‰ê¸ˆ ê´€ë ¨ì¸ë° ê¸ˆì•¡ì„ ì§ì–¸í•˜ì§€ ì•Šìœ¼ë©´ TERMS ìª½ìœ¼ë¡œ
        if "í™˜ê¸‰" in q or "í™˜ë¶ˆ" in q or "í•´ì§€í™˜ê¸‰" in q:
            result["primary_flow"] = "TERMS"

    # (C) ì—”í‹°í‹°ê°€ ì¡´ì¬í•˜ë©´ TERMSì—ì„œ retrieval_suggestion ê°•ì œ ON
    if result.get("primary_flow") == "TERMS" and (insurer or product):
        result["retrieval_suggestion"] = "on"

    # (D) ìš”ì•½ textì— ì—”í‹°í‹°ê°€ ë¹ ì§€ë©´ ë³´ì™„(í”„ë¡¬í”„íŠ¸ê°€ ë³´ì¥í•´ë„ ê°€ë” ë¹ ì§)
    summary = (result.get("text") or "").strip()
    if (insurer or product) and summary:
        if insurer and insurer not in summary:
            summary = f"{insurer} " + summary
        if product and product not in summary:
            summary = f"{summary} (ìƒí’ˆ: {product})"
        result["text"] = summary

    # (E) íƒœê·¸ ë³´ê°•
    tags = result.get("tags") or []
    if "í™˜ê¸‰ê¸ˆ" not in tags and ("í™˜ê¸‰" in q or "í•´ì§€í™˜ê¸‰" in q):
        tags.append("í™˜ê¸‰ê¸ˆ")
    if (insurer or product) and "ì•½ê´€" not in tags and result.get("primary_flow") == "TERMS":
        tags.append("ì•½ê´€")
    result["tags"] = list(dict.fromkeys(tags))  # ì¤‘ë³µ ì œê±°
    # ===== ë³´ì • ë =====

    return result

# ================== ìµœì¢… Answerer LLM (chat.py í˜¸í™˜) ==================
def run_llm(messages: List[Dict[str, str]]) -> str:
    resp = _client.chat.completions.create(
        model=ANSWERER_MODEL,
        messages=messages,
        temperature=0.2,
    )
    return (resp.choices[0].message.content or "").strip()

async def call_llm(messages: List[Dict[str, str]]) -> str:
    return await asyncio.to_thread(run_llm, messages)
